{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70f23888",
   "metadata": {},
   "source": [
    "Before doing anything below, be sure to install the conda environment: `conda env create -f tvae.yml`, then add the environment to your jupyter configuration `python -m ipykernel install --user --name=tvae`. When launching the notebook, be sure to select the `tvae` environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a13d7e1",
   "metadata": {},
   "source": [
    "# Model, training, and device configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "640e9b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import *\n",
    "# Example model arguments\n",
    "model_config = { \n",
    "    \"name\": \"tvae\",\n",
    "    \"z_dim\": 32, \n",
    "    \"h_dim\": 256,\n",
    "    \"rnn_dim\": 256,\n",
    "    \"num_layers\": 1,\n",
    "    \"in_state_dim\": 28, \n",
    "    \"in_action_dim\": 28, \n",
    "    \"out_state_dim\": 14, \n",
    "    \"out_action_dim\": 14\n",
    "}\n",
    "\n",
    "# Example training arguments\n",
    "train_config = { \n",
    "    \"batch_size\": 128,\n",
    "    \"num_epochs_til_val\": 10, \n",
    "    \"learning_rate\": 0.0002,\n",
    "    \"num_epochs\": 300,\n",
    "    \"clip\": 10, \n",
    "    'comet_ml_key': '',\n",
    "    \"project_name\": 'test_jupyter_notebook'\n",
    "}  \n",
    "\n",
    "# Device configurations\n",
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d24726",
   "metadata": {},
   "source": [
    "# Dataset configurations and loading\n",
    "Before completing this step, you must save the input and output data arrays in `.npz` format. The dimensions of the input data array should be [`num_samples`, `sequence_length`, `in_state_dim`] and the output array should be [`num_samples`, `sequence_length`, `out_state_dim`]. Use `np.savez()` to save the arrays to the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62bec59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths to the npz arrays with your desired inputs and outputs\n",
    "root_data_dir = '/media/storage/andrew/data/autism_dataset/10_10/both_in_forecast_res/'\n",
    "data_in_path = os.path.join(root_data_dir, 'data_in.npz')\n",
    "data_out_path = os.path.join(root_data_dir, 'data_out.npz')\n",
    "\n",
    "# val_prop controls the proportion of the validation set relative to all data\n",
    "data_config = { \n",
    "    'name': 'mouse_v1',\n",
    "    'in_file': data_in_path,\n",
    "    'out_file': data_out_path,\n",
    "}   \n",
    "# build dataset and train / val split\n",
    "dataset = load_dataset(data_config)\n",
    "data_loader = DataLoader(\n",
    "                dataset,\n",
    "                batch_size=train_config['batch_size'],\n",
    "                shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a546754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will check and store the most recent checkpointed model in your project directory\n",
    "train_config = checkpoint_handler(train_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e328c0",
   "metadata": {},
   "source": [
    "# Model instantiation and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66bcbabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TVAE(model_config)\n",
    "model = model.to(device)\n",
    "model.prepare_stage(train_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd84c1df",
   "metadata": {},
   "source": [
    "# Run training\n",
    "If you set the `comet_ml_key` in the first step correctly, than logging information will be at the URL provided below. Checkpoints will be saved to `./checkpoints/<YOUR PROJECT NAME>/epoch #`. Checkpoints get saved every time validation is run which is set in `train_config[num_epochs_til_val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0c1d093",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET ERROR: The given API key  is invalid, please check it against the dashboard. Your experiment would not be logged \n",
      "For more details, please refer to: https://www.comet.ml/docs/python-sdk/warnings-errors/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-=-=-= EPOCH 40 OF 300 =-=-=-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 36/5066 [00:05<12:05,  6.94it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8df220708434>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tvae/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, train_config, device)\u001b[0m\n\u001b[1;32m     71\u001b[0m                                 \u001b[0mout_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \t\t\t\tbatch_log = model(\n\u001b[0m\u001b[1;32m     74\u001b[0m                                         \u001b[0min_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                                         \u001b[0min_actions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tvae/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tvae/lib/models/core.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, in_states, in_actions, target_states, target_actions, reconstruct, num_samples, chain, embed)\u001b[0m\n\u001b[1;32m    298\u001b[0m                         \u001b[0;31m# Update recurrent units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_recurrent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tvae/lib/models/core.py\u001b[0m in \u001b[0;36mupdate_hidden\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_recurrent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mstate_action_pair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mhiddens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_action_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, data_loader, train_config, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c9596c",
   "metadata": {},
   "source": [
    "# Loading model checkpoints\n",
    "There is not currently code for selecting which model checkpoint has the lowest validation loss - that is on the todo list. For now, you should look at comet ML graphs and select the one with the lowest validation NLL. Once you have done that all you need to do to load in a model is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb456dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"<YOUR CHECKPOINT PATH HERE>\"\n",
    "\n",
    "model.load_state_dict(torch.load(checkpoint_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef98c12",
   "metadata": {},
   "source": [
    "# Generating Reconstructions and Embeddings\n",
    "This step assumes that you have chosen which model checkpoint you want to use to generate embeddings and reconstructions. This method will generate `num_reconstruction` samples from the posterior distribution predicted by the encoder, and then select the sample with the lowest negative log likelihood as the reconstruction of the corresponding original. Each embedding in embeddings is the mean of the posterior distribution used to generate the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540bb6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reconstruct import reconstruct\n",
    "\n",
    "num_reconstructions = 10 \n",
    "reconstructions, originals, embeddings = reconstruct(model, data_loader, device, num_reconstructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67436221",
   "metadata": {},
   "source": [
    "# Plotting reconstructions against originals\n",
    "After running the code below, you can check the gif located at the path you specified to see if the reconstruction matches the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7451c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.plotting.plot_seq import plot_reconstruction\n",
    "\n",
    "idx = 3 # arbitrary test reconstruction\n",
    "plot_reconstruction(originals[idx], reconstructions[idx], path='./gifs/test.gif') # Good idea to store your gifs in their own folder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvae",
   "language": "python",
   "name": "tvae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
